#include <iostream>
// #include "Signatures.cpp"
#include "Index.cpp"
#include "args.h"
#include "utils.h"
#include <seqan/seq_io.h>
#include <seqan/sequence.h>

//Standard namespace declaration
using namespace std;

void printUsage()
{
    std::cerr
        << "usage: metaMLP <command> <args>\n\n"
        << "The commands supported by metaMLP are:\n\n"
        << "  index              Index the reference sequences\n"
        << "  quant              Run quantification algorithm [prediction]\n"
        << std::endl;
}

void printPredictUsage()
{
    std::cerr
        << "usage: metaMLP quant <args>\n\n"
        << "The commands supported by metaMLP quant are:\n\n"
        << "  -model            Trained model - generated by metaMLP index\n"
        << "  -input            FASTA file with short sequence reads\n"
        << "  -output           output file to write the processed reads\n"
        << "  -kmer             k-mer size [default 11] same used during index\n\n"

        << "Optional Parameters: \n\n"

        << "  -tries            sensitivity [default 2] higher gives more hits more errors\n"
        << "  -minProbability   minimum probability to report sequences [default 0.8]\n"
        << "  -threads          number of threads to use\n"
        << "  -minReadChunkSize Load reads in memory [default 10000]\n\n"

        << "Optional Alphabet Parameters: \n\n"
        << "  -NoReduced        Enable it if index is built with the -NoReduced option\n\n"

        << "Optional Output: \n\n"
        << "  -fastaOutput    save fasta file with predicted sequences [default False]\n"
        << std::endl;
}

void printIndexUsage()
{
    std::cerr
        << "usage: metaMLP index <args>\n\n"
        << "Mandatory Parameters:\n\n"
        << "  -input        Protein reference database\n"
        << "  -output       Output index\n"
        << "  -kmer         k-mer size (aminoacids) [default 11]\n"
        << "  -labp         Label index position in the FASTA header (default 4: >xx|xx|xx|label|xx)\n"
        << "                for multiple labels use ; >xx|xx|xx|label1;label2;label3|xx|xx\n\n"
        << "Optional Training Parameters: \n\n"

        << "  -dim          word vector size [default 64] adjust for large number of classes\n"
        << "  -epoch        number of epochs for training the model [default 100]\n"
        << "  -lr           learning rate [default 1]\n"
        << "  -minn         minimum length of kmer ngram [default 3]\n"
        << "  -maxn         maximum length of kmer ngram [default 7]\n"
        << "  -ws           size of context window for building embeddings [default 5]\n"
        << "  -minCount     minimum ngram count [default 1]\n"
        << "  -wordNgrams   embedding joint ngrams [default 1]\n"
        << "  -loss         loss function {ns, hs, softmax} [default softmax]\n\n"

        << "Optional Alphabet Parameters: \n\n"
        << "  -NoReduced    Dissable the reduced alphabet and use all 20 Amino Acids\n\n"

        << std::endl;
}

void printPrintSentenceVectorsUsage()
{
    std::cerr
        << "usage: fasttext print-sentence-vectors <model>\n\n"
        << "  <model>      model filename\n"
        << std::endl;
}

void compute_absolute_abundance()
{
}

template <typename Out>
void splitx(const std::string &s, char delim, Out result)
{
    std::stringstream ss;
    ss.str(s);
    std::string item;
    while (std::getline(ss, item, delim))
    {
        *(result++) = item;
    }
}

std::vector<std::string> splitx(const std::string &s, char delim)
{
    std::vector<std::string> elems;
    splitx(s, delim, std::back_inserter(elems));
    return elems;
}

void quant(int argc, char **argv)
{
    // load parameters
    std::shared_ptr<fasttext::Args> a = std::make_shared<fasttext::Args>();
    a->parseArgs(argc, argv);

    // start fasttext
    fasttext::FastText fastText;

    std::cout << "Loading kmers ... \n";

    std::ifstream ifs(a->smodel + ".kh");
    std::string line;
    std::vector<std::string> iline;

    while (std::getline(ifs, line))
    {
        iline = splitx(line, '\t');
        a->master_signature_hash_full[iline[0]] = true;
    }
    ifs.close();

    std::cout << "loading model ..." << std::endl;
    std::string model_file = a->smodel + ".bin";
    fastText.loadModel(model_file);
    std::cout << "Predicting ... \n";

    // fastText.map(a);
}

void index(int argc, char **argv)
{
    if (argc < 3)
    {
        printIndexUsage();
        exit(0);
    }

    std::shared_ptr<fasttext::Args> a = std::make_shared<fasttext::Args>();
    a->parseArgs(argc, argv);
    Index index;
    index.indexing(a->input, a->output, a->kmer, a->labp - 1, a->reduced);

    // training model
    std::cout << "Indexing reference database ..." << std::endl;
    fasttext::FastText fastText;

    a->model = fasttext::model_name::sup;
    a->loss = fasttext::loss_name::hs;
    a->input = a->output + ".tr";
    // a->epoch = 100;
    // a->lr = 1;
    // a->minCount = 1;
    // a->tries = 5;
    // a->dim = 100;
    // a->wordNgrams = 2;
    fastText.train(a);

    std::cout << "Cleaning temporal files ..." << std::endl;
    // remove(a->input.c_str());

    exit(0);
}

void printSentenceVectors(int argc, char **argv)
{
    if (argc != 3)
    {
        printPrintSentenceVectorsUsage();
        exit(EXIT_FAILURE);
    }
    fasttext::FastText fasttext;
    fasttext.loadModel(std::string(argv[2]));
    fasttext.printSentenceVectors();
    exit(0);
}

//Main Function
int main(int argc, char **argv)
{
    if (argc < 2)
    {
        printUsage();
        exit(0);
    }

    std::string command(argv[1]);
    if (command == "index")
    {
        index(argc, argv);
    }
    else if (command == "quant")
    {
        quant(argc, argv);
    }
    else if (command == "print-word-vectors")
    {
        printSentenceVectors(argc, argv);
    }
    else
    {
        printUsage();
        exit(0);
    }

    return 0;
}
